<!-- RULEBOOK:START -->
# Project Rules

Generated by @hivellm/rulebook
Generated at: 2025-10-23T21:27:13.868Z

## Documentation Standards

**CRITICAL**: Minimize Markdown files. Keep documentation organized.

### Allowed Root-Level Documentation
Only these files are allowed in the project root:
- ✅ `README.md` - Project overview and quick start
- ✅ `CHANGELOG.md` - Version history and release notes
- ✅ `AGENTS.md` - This file (AI assistant instructions)
- ✅ `LICENSE` - Project license
- ✅ `CONTRIBUTING.md` - Contribution guidelines
- ✅ `CODE_OF_CONDUCT.md` - Code of conduct
- ✅ `SECURITY.md` - Security policy

### All Other Documentation
**ALL other documentation MUST go in `/docs` directory**:
- `/docs/ARCHITECTURE.md` - System architecture
- `/docs/DEVELOPMENT.md` - Development guide
- `/docs/ROADMAP.md` - Project roadmap
- `/docs/DAG.md` - Component dependencies (DAG)
- `/docs/specs/` - Feature specifications
- `/docs/sdks/` - SDK documentation
- `/docs/protocols/` - Protocol specifications
- `/docs/guides/` - Developer guides
- `/docs/diagrams/` - Architecture diagrams
- `/docs/benchmarks/` - Performance benchmarks
- `/docs/versions/` - Version release reports

## Testing Requirements

**CRITICAL**: All features must have comprehensive tests.

- **Minimum Coverage**: 95%
- **Test Location**: `/tests` directory in project root
- **Test Execution**: 100% of tests MUST pass before moving to next task
- **Test First**: Write tests based on specifications before implementation

## Feature Development Workflow

**CRITICAL**: Follow this workflow for all feature development.

1. **Check Specifications First**:
   - Read `/docs/specs/` for feature specifications
   - Review `/docs/ARCHITECTURE.md` for system design
   - Check `/docs/ROADMAP.md` for implementation timeline
   - Review `/docs/DAG.md` for component dependencies

2. **Implement with Tests**:
   - Write tests in `/tests` directory first
   - Implement feature following specifications
   - Ensure tests pass and meet coverage threshold

3. **Quality Checks**:
   - Run code formatter
   - Run linter (must pass with no warnings)
   - Run all tests (must be 100% passing)
   - Verify coverage meets threshold

4. **Update Documentation**:
   - Update `/docs/ROADMAP.md` progress
   - Update feature specs if implementation differs
   - Document any deviations with justification

## Rules Configuration

Rules can be selectively disabled using `.rulesignore` file in project root.

Example `.rulesignore`:
```
# Ignore coverage requirement
coverage-threshold
# Ignore specific language rules
rust/edition-2024
# Ignore all TypeScript rules
typescript/*
```

<!-- RULEBOOK:END -->


<!-- TYPESCRIPT:START -->
# TypeScript Project Rules

## TypeScript Configuration

**CRITICAL**: Use TypeScript 5.3+ with strict mode enabled.

- **Version**: TypeScript 5.3+
- **Mode**: Strict mode enabled
- **Target**: ES2022 or later
- **Module**: ESNext with Node16 module resolution

### tsconfig.json Requirements

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ESNext",
    "moduleResolution": "node",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": true
  }
}
```

## Code Quality Standards

### Mandatory Quality Checks

**CRITICAL**: After implementing ANY feature, you MUST run these commands in order:

```bash
# 1. Type check
npm run type-check  # or: tsc --noEmit

# 2. Lint (MUST pass with no warnings)
npm run lint

# 3. Format code
npm run format

# 4. Run all tests (MUST pass 100%)
npm test

# 5. Check coverage (MUST meet threshold)
npm run test:coverage
```

**If ANY of these fail, you MUST fix the issues before committing.**

### Linting

- Use ESLint with TypeScript plugin
- Configuration in `eslint.config.js` or `.eslintrc.json`
- Must pass with no warnings: `eslint src/**/*.ts`
- Fix automatically when possible: `eslint src/**/*.ts --fix`

Example ESLint config:
```json
{
  "extends": [
    "eslint:recommended",
    "plugin:@typescript-eslint/recommended"
  ],
  "parser": "@typescript-eslint/parser",
  "plugins": ["@typescript-eslint"],
  "rules": {
    "@typescript-eslint/no-unused-vars": ["error", { "argsIgnorePattern": "^_" }],
    "@typescript-eslint/explicit-function-return-type": "warn",
    "@typescript-eslint/no-explicit-any": "warn"
  }
}
```

### Formatting

- Use Prettier for code formatting
- Configuration in `.prettierrc.json`
- Integrate with ESLint for consistency
- Format before committing: `prettier --write "src/**/*.ts"`

Example Prettier config:
```json
{
  "semi": true,
  "trailingComma": "es5",
  "singleQuote": true,
  "printWidth": 100,
  "tabWidth": 2
}
```

### Testing

- **Framework**: Vitest (recommended) or Jest
- **Location**: `/tests` directory or co-located `*.test.ts` files
- **Coverage**: Must meet project threshold (default 95%)
- **Watch Mode**: Use `vitest --watch` for development

Example test structure:
```typescript
import { describe, it, expect, beforeEach, afterEach } from 'vitest';
import { myFunction } from './my-module';

describe('myFunction', () => {
  beforeEach(() => {
    // Setup
  });

  afterEach(() => {
    // Cleanup
  });

  it('should handle valid input', () => {
    const result = myFunction('input');
    expect(result).toBe('expected');
  });

  it('should throw on invalid input', () => {
    expect(() => myFunction('')).toThrow('Invalid input');
  });
});
```

## Package Management

**CRITICAL**: Use consistent package manager across team.

- **Default**: npm (most compatible, built-in)
- **Alternative**: pnpm (fast, disk-efficient) or yarn
- **Lockfile**: Always commit lockfile (`package-lock.json`, `pnpm-lock.yaml`, or `yarn.lock`)
- **Workspaces**: Use for monorepos
- **CI/CD**: Update GitHub Actions workflows to match your package manager (see workflow comments)

### Dependencies

1. **Check for latest versions**:
   - Use Context7 MCP tool if available
   - Check npm registry: `npm view <package> versions`
   - Review changelog for breaking changes

2. **Dependency Guidelines**:
   - ✅ Use exact versions for applications (`"1.2.3"`)
   - ✅ Use semver for libraries (`"^1.2.3"`)
   - ✅ Keep dependencies updated regularly
   - ✅ Use `npm audit` or `pnpm audit` for security
   - ❌ Don't use deprecated packages
   - ❌ Don't add unnecessary dependencies

3. **Document new dependencies**:
   - Update CHANGELOG.md
   - Document why dependency was added
   - Note any peer dependencies

## Type Safety

- **No `any`**: Avoid `any` type - use `unknown` and type guards
- **Strict null checks**: Handle null/undefined explicitly
- **Type assertions**: Minimize use of `as` - prefer type guards
- **Generics**: Use for reusable type-safe code

Example type-safe code:
```typescript
// Good: Type guard
function isString(value: unknown): value is string {
  return typeof value === 'string';
}

function process(input: unknown): string {
  if (isString(input)) {
    return input.toUpperCase();
  }
  throw new Error('Invalid input');
}

// Bad: Type assertion
function processUnsafe(input: unknown): string {
  return (input as string).toUpperCase(); // Runtime error if not string
}
```

## Error Handling

- Create custom error classes
- Use type guards for error checking
- Document errors in JSDoc/TSDoc
- Never swallow errors silently

Example:
```typescript
export class ValidationError extends Error {
  constructor(
    message: string,
    public readonly field: string
  ) {
    super(message);
    this.name = 'ValidationError';
  }
}

export function validate(data: unknown): Data {
  if (!isValidData(data)) {
    throw new ValidationError('Invalid data structure', 'data');
  }
  return data;
}
```

## Documentation

- **JSDoc/TSDoc**: Document public APIs
- **Examples**: Include usage examples
- **Type exports**: Export types for library consumers
- **README**: Include API documentation

Example:
```typescript
/**
 * Processes the input data and returns a formatted result.
 *
 * @param input - The input string to process
 * @param options - Optional processing options
 * @returns The processed string in uppercase
 * @throws {ValidationError} If input is empty
 *
 * @example
 * ```typescript
 * const result = process('hello', { trim: true });
 * console.log(result); // 'HELLO'
 * ```
 */
export function process(
  input: string,
  options?: ProcessOptions
): string {
  // Implementation
}
```

## Project Structure

```
project/
├── package.json        # Package manifest
├── tsconfig.json       # TypeScript config
├── vitest.config.ts    # Test config
├── README.md           # Project overview (allowed in root)
├── CHANGELOG.md        # Version history (allowed in root)
├── AGENTS.md          # AI assistant rules (allowed in root)
├── LICENSE            # Project license (allowed in root)
├── CONTRIBUTING.md    # Contribution guidelines (allowed in root)
├── CODE_OF_CONDUCT.md # Code of conduct (allowed in root)
├── SECURITY.md        # Security policy (allowed in root)
├── src/
│   ├── index.ts        # Main entry point
│   ├── types.ts        # Type definitions
│   └── ...
├── tests/              # Test files
├── dist/               # Compiled output (gitignored)
└── docs/               # Project documentation
```

## Module System

- Use ES modules (`import`/`export`)
- Set `"type": "module"` in `package.json`
- Use `.js` extensions in imports for Node.js compatibility
- Configure `moduleResolution: "node"` in tsconfig.json

Example:
```typescript
// Good: ES modules with .js extension
import { myFunction } from './my-module.js';

export { myFunction };
export default class MyClass {}
```

## CI/CD Requirements

Must include GitHub Actions workflows for:

1. **Testing** (`typescript-test.yml`):
   - Test on ubuntu-latest, windows-latest, macos-latest
   - Use Vitest for fast execution
   - Upload coverage reports

2. **Linting** (`typescript-lint.yml`):
   - Type check: `tsc --noEmit`
   - ESLint: `eslint src/**/*.ts`
   - Prettier: `prettier --check "src/**/*.ts"`

3. **Build** (`typescript-build.yml`):
   - Build: `npm run build`
   - Verify no type errors
   - Check output artifacts

## Package Publication

### Publishing to npm

**Prerequisites:**
1. Create npm account at https://www.npmjs.com
2. Generate npm token (Account Settings → Access Tokens → Generate New Token)
3. Add `NPM_TOKEN` to GitHub repository secrets

**package.json Configuration:**

```json
{
  "name": "@your-org/package-name",
  "version": "1.0.0",
  "description": "Package description",
  "main": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "type": "module",
  "exports": {
    ".": {
      "types": "./dist/index.d.ts",
      "import": "./dist/index.js"
    }
  },
  "files": [
    "dist",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "prepublishOnly": "npm run build && npm test"
  },
  "keywords": ["your", "keywords"],
  "author": "Your Name",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/your-org/package-name"
  }
}
```

**Publishing Workflow:**

1. Update version: `npm version patch|minor|major`
2. Create release tag: `git push --tags`
3. GitHub Actions automatically publishes to npm
4. Or manual publish: `npm publish --access public`

**Publishing Checklist:**

- ✅ All tests passing
- ✅ Code linted and formatted
- ✅ Version updated in package.json
- ✅ CHANGELOG.md updated
- ✅ README.md up to date
- ✅ Type declarations generated
- ✅ Package size reasonable (`npm pack` to check)
- ✅ .npmignore or package.json "files" configured
- ✅ Provenance enabled for security

**npm Provenance:**

Enable provenance for better security and transparency:
```bash
npm publish --provenance --access public
```

This links your package to its source code and build process.

<!-- TYPESCRIPT:END -->



<!-- VECTORIZER:START -->
# Vectorizer Instructions

**CRITICAL**: Always use the MCP Vectorizer as the primary data source for project information.

The vectorizer provides fast, semantic access to the entire codebase. Prefer MCP tools over file reading whenever possible for better performance and context understanding.

## Primary Search Functions

### 1. mcp_vectorizer_search

Main search interface with multiple strategies:

- `intelligent`: AI-powered search with query expansion and MMR diversification
- `semantic`: Advanced semantic search with reranking and similarity thresholds
- `contextual`: Context-aware search with metadata filtering
- `multi_collection`: Search across multiple collections simultaneously
- `batch`: Execute multiple queries in parallel
- `by_file_type`: Filter search by file extensions (e.g., `.rs`, `.ts`, `.py`)

**Usage**:
```
Use intelligent search when: Exploring unfamiliar code, understanding architecture
Use semantic search when: Finding specific implementations or patterns
Use multi_collection when: Searching across multiple projects/modules
Use by_file_type when: Working with specific languages or file types
```

### 2. mcp_vectorizer_file_operations

File-specific operations for efficient file handling:

- `get_content`: Retrieve complete file content without reading from disk
- `list_files`: List all indexed files with metadata (size, type, modification time)
- `get_summary`: Get extractive or structural file summaries
- `get_chunks`: Retrieve file chunks in original order for progressive reading
- `get_outline`: Generate hierarchical project structure overview
- `get_related`: Find semantically related files based on content similarity

**Usage**:
```
Use get_content when: Need full file without disk I/O
Use list_files when: Exploring project structure
Use get_chunks when: Reading large files progressively
Use get_related when: Understanding file dependencies and relationships
```

### 3. mcp_vectorizer_discovery

Advanced discovery pipeline for complex queries:

- `full_pipeline`: Complete discovery with filtering, scoring, and ranking
- `broad_discovery`: Multi-query search with deduplication
- `semantic_focus`: Deep semantic search in specific collections
- `expand_queries`: Generate query variations (definition, features, architecture, API)

**Usage**:
```
Use full_pipeline when: Complex multi-faceted questions
Use broad_discovery when: Need comprehensive coverage of a topic
Use expand_queries when: Uncertain about exact terminology
```

## Best Practices

1. **Start with intelligent search** for exploratory queries to understand codebase structure
2. **Use file_operations** when you need complete file context without disk access
3. **Use discovery pipeline** for complex, multi-faceted questions requiring deep analysis
4. **Prefer batch operations** when searching for multiple related items to reduce latency
5. **Use by_file_type** when working with specific languages (e.g., only Rust or TypeScript files)

## Performance Tips

- **Batch queries** instead of sequential searches for better performance
- **Use specific collections** when you know the target area to reduce search space
- **Set similarity thresholds** to filter out irrelevant results (typically 0.6-0.8)
- **Cache results** for repeated queries within the same session

## Common Patterns

### Pattern 1: Understanding a Feature
```
1. Use intelligent search to find feature implementation
2. Use get_related to find connected files
3. Use get_outline to understand feature structure
4. Use get_content to read specific implementations
```

### Pattern 2: Debugging an Issue
```
1. Use semantic search with error message or symptom
2. Use by_file_type to focus on relevant language files
3. Use get_chunks to progressively read large files
4. Use get_related to find potentially affected files
```

### Pattern 3: Adding a New Feature
```
1. Use expand_queries to find similar existing features
2. Use full_pipeline for comprehensive discovery
3. Use get_outline to understand where to add code
4. Use get_related to find integration points
```

<!-- VECTORIZER:END -->



<!-- SYNAP:START -->
# Synap Instructions

**CRITICAL**: Use MCP Synap for persistent task and data storage during development sessions.

Synap provides a distributed key-value store, pub/sub messaging, and streaming capabilities. Use it to maintain state, track tasks, and persist important data across context windows.

## Core Features

### 1. Key-Value Store

Store and retrieve data with TTL support:

- `synap_kv_get`: Retrieve a value by key
- `synap_kv_set`: Store a value with optional TTL (time-to-live)
- `synap_kv_delete`: Remove a key from storage
- `synap_kv_scan`: Scan keys by prefix pattern

**Usage**:
```
Use for: Task tracking, configuration storage, session state
TTL for: Temporary data that should expire
Scan for: Listing related items by prefix (e.g., "task:*")
```

### 2. Queue System

Persistent message queues for task management:

- `synap_queue_publish`: Add a message to a queue with priority
- `synap_queue_consume`: Retrieve and process messages from queue

**Usage**:
```
Use for: Task queues, work distribution, async job processing
Priorities: 0-9 (9 = highest priority)
Pattern: Producer-consumer model for parallel work
```

### 3. Pub/Sub Messaging

Event-driven communication:

- `synap_pubsub_publish`: Broadcast message to topic subscribers

**Usage**:
```
Use for: Event notifications, real-time updates, broadcast messages
Pattern: One-to-many messaging for loosely coupled components
```

### 4. Streaming

Real-time event streaming:

- `synap_stream_publish`: Publish events to a stream room

**Usage**:
```
Use for: Real-time data streams, live updates, event logs
Pattern: Continuous data flow for monitoring and analytics
```

## Best Practices for AI Development

### Task Tracking

Store implementation tasks and progress:

```
Pattern: "task:<feature-name>:<subtask-id>"

Example:
- synap_kv_set("task:auth:implement-login", JSON.stringify({
    status: "in_progress",
    started: "2024-01-01T10:00:00Z",
    tests: ["test_login_success", "test_login_failure"],
    coverage: 95.2
  }))
```

### Session State

Preserve state across context windows:

```
Pattern: "session:<session-id>:<data-type>"

Example:
- synap_kv_set("session:abc123:current-file", "/src/auth/login.ts")
- synap_kv_set("session:abc123:todo-list", JSON.stringify([...]))
```

### Configuration Storage

Store project configuration and settings:

```
Pattern: "config:<category>:<key>"

Example:
- synap_kv_set("config:project:coverage-threshold", "95")
- synap_kv_set("config:project:languages", JSON.stringify(["rust", "typescript"]))
```

### Test Results

Track test execution and coverage:

```
Pattern: "test:<suite>:<timestamp>"

Example:
- synap_kv_set("test:integration:latest", JSON.stringify({
    passed: 42,
    failed: 0,
    coverage: 96.5,
    duration: "3.2s"
  }), 86400) // TTL: 24 hours
```

## Common Patterns

### Pattern 1: Multi-Step Implementation Tracking

```
1. Store overall plan: synap_kv_set("plan:feature-x", plan_json)
2. Track each step: synap_kv_set("step:feature-x:1", step_status)
3. Update progress: synap_kv_set("progress:feature-x", percentage)
4. Mark complete: synap_kv_delete("plan:feature-x")
```

### Pattern 2: Code Generation History

```
1. Store generated code: synap_kv_set("generated:file-path", code)
2. Track modifications: synap_kv_set("history:file-path", changelog)
3. List all generated: synap_kv_scan("generated:*")
```

### Pattern 3: Error Tracking

```
1. Log errors: synap_kv_set("error:timestamp", error_details, 3600)
2. Track fixes: synap_kv_set("fix:error-id", fix_details)
3. Scan recent errors: synap_kv_scan("error:*")
```

## Retention and Cleanup

- Use TTL for temporary data (session state, cache, recent errors)
- No TTL for persistent data (configuration, important results)
- Regularly clean up old data with `synap_kv_delete`
- Use prefixes for easy bulk operations with `synap_kv_scan`

## Integration with Development Workflow

1. **Before Starting**: Check for existing state (`synap_kv_get("session:current-task")`)
2. **During Work**: Update progress regularly (`synap_kv_set("progress:*")`)
3. **After Completion**: Store results and clean up temporary data
4. **Context Switch**: Save complete state before summarization

<!-- SYNAP:END -->



<!-- CONTEXT7:START -->
# Context7 Instructions

**CRITICAL**: Use MCP Context7 to access up-to-date library documentation before adding dependencies.

Context7 provides real-time access to documentation for thousands of libraries and frameworks. Always check Context7 before adding new dependencies to ensure you're using the latest stable versions and following best practices.

## Core Functions

### 1. resolve-library-id

Resolve a package name to a Context7-compatible library ID:

```
Input: Library name (e.g., "tokio", "react", "fastapi")
Output: Context7 library ID (e.g., "/tokio-rs/tokio", "/facebook/react")
```

**MUST** use this function before `get-library-docs` unless the user provides an explicit library ID.

### 2. get-library-docs

Fetch documentation for a library:

```
Input: Context7 library ID, optional topic, token limit
Output: Relevant documentation, examples, API reference
```

Options:
- `topic`: Focus on specific area (e.g., "routing", "hooks", "async")
- `tokens`: Control documentation size (default: 5000)

## Mandatory Usage

### Before Adding Dependencies

**CRITICAL**: Check Context7 for every new dependency.

#### Rust Example
```
Adding tokio:
1. resolve-library-id("tokio") → "/tokio-rs/tokio"
2. get-library-docs("/tokio-rs/tokio") → Latest version, features, examples
3. Check for breaking changes in latest version
4. Add to Cargo.toml with correct version and features
```

#### TypeScript Example
```
Adding express:
1. resolve-library-id("express") → "/expressjs/express"
2. get-library-docs("/expressjs/express") → Latest version, middleware patterns
3. Review TypeScript type definitions availability
4. Add to package.json with latest stable version
```

#### Python Example
```
Adding fastapi:
1. resolve-library-id("fastapi") → "/tiangolo/fastapi"
2. get-library-docs("/tiangolo/fastapi", topic="async") → Async patterns
3. Check Python version requirements
4. Add to pyproject.toml or requirements.txt
```

## Best Practices

### 1. Version Verification

Always verify the latest stable version:

```
1. Use resolve-library-id to find the library
2. Use get-library-docs to see current version
3. Check for security advisories
4. Review changelog for breaking changes
5. Document version choice in code/commits
```

### 2. Topic-Focused Queries

Use the topic parameter for specific information:

```
Examples:
- get-library-docs("/tokio-rs/tokio", topic="channels")
- get-library-docs("/facebook/react", topic="hooks")
- get-library-docs("/psf/requests", topic="authentication")
```

### 3. Migration Guides

When updating major versions:

```
1. Get docs for current version
2. Get docs for target version
3. Look for migration guide in documentation
4. Review breaking changes
5. Plan migration strategy
```

### 4. Best Practices Discovery

Learn idiomatic usage patterns:

```
1. Get library docs with relevant topic
2. Review code examples
3. Check for recommended patterns
4. Follow security best practices
5. Implement according to documentation
```

## Integration with Development Workflow

### Adding New Dependency

```
1. Identify need for library
2. Use resolve-library-id to find correct library
3. Use get-library-docs to review:
   - Latest stable version
   - Features and capabilities
   - Usage examples
   - Security considerations
4. Add dependency with correct version
5. Document why this library was chosen
6. Update CHANGELOG.md
```

### Updating Existing Dependency

```
1. Use get-library-docs for current version
2. Use get-library-docs for latest version
3. Review changelog between versions
4. Check for breaking changes
5. Update code if needed
6. Update dependency version
7. Test thoroughly
```

### Troubleshooting

```
1. Use get-library-docs with specific topic
2. Search for error message or issue
3. Review examples for correct usage
4. Check for known issues or workarounds
5. Verify you're following best practices
```

## Common Patterns

### Pattern 1: Dependency Selection

```
Problem: Need HTTP client library

1. resolve-library-id("requests") for Python
   OR resolve-library-id("reqwest") for Rust
   OR resolve-library-id("axios") for TypeScript

2. get-library-docs for each candidate

3. Compare features, performance, maintenance

4. Choose best fit for requirements

5. Document decision
```

### Pattern 2: Feature Discovery

```
Need: Async file operations in Rust

1. resolve-library-id("tokio") → "/tokio-rs/tokio"
2. get-library-docs("/tokio-rs/tokio", topic="file I/O")
3. Review async file operation examples
4. Implement using documented patterns
```

### Pattern 3: Security Verification

```
Before adding crypto library:

1. resolve-library-id("ring") for Rust
2. get-library-docs("/briansmith/ring")
3. Check security audit status
4. Review recommended algorithms
5. Verify actively maintained
6. Add with appropriate features
```

## Library ID Format

Context7 library IDs follow patterns:

- GitHub: `/org/repo` or `/org/repo/version`
- Examples:
  - `/tokio-rs/tokio`
  - `/vercel/next.js`
  - `/psf/requests`
  - `/vercel/next.js/v14.0.0` (specific version)

## Error Handling

If library not found:

1. Verify correct library name
2. Try alternative names or repos
3. Check if library is on supported platforms
4. Consider using official documentation as fallback

<!-- CONTEXT7:END -->



<!-- GIT:START -->

**AI Assistant Git Push Mode**: MANUAL

**CRITICAL**: Never execute `git push` commands automatically.
Always provide push commands for manual execution by the user.

Example:
```
✋ MANUAL ACTION REQUIRED:
Run these commands manually (SSH password may be required):
  git push origin main
  git push origin v1.0.0
```

# Git Workflow Rules

**CRITICAL**: Specific rules and patterns for Git version control workflow.

## Git Workflow Overview

This project follows a strict Git workflow to ensure code quality and proper version control.

**NEVER commit code without tests passing. NEVER create tags without full quality checks.**

## Initial Repository Setup

### New Project Initialization

**⚠️ CRITICAL**: Only run initialization commands if `.git` directory does NOT exist!

```bash
# Check if Git repository already exists
if [ -d .git ]; then
  echo "❌ Git repository already initialized. Skipping git init."
  echo "Current status:"
  git status
  git remote -v
  exit 0
fi

# If no .git directory exists, initialize:

# Initialize Git repository
git init

# Add all files
git add .

# Initial commit
git commit -m "chore: Initial project setup"

# Rename default branch to main (GitHub standard)
git branch -M main

# Add remote (if applicable)
git remote add origin <repository-url>
```

**AI Assistant Behavior:**

```
BEFORE running any Git initialization commands:

1. Check if .git directory exists
2. If exists:
   ✅ Repository already configured
   ❌ DO NOT run: git init
   ❌ DO NOT run: git branch -M main
   ✅ Check status: git status
   ✅ Show remotes: git remote -v
   
3. If not exists:
   ✅ Safe to initialize
   ✅ Run full initialization sequence
```

## AI Assistant Git Checks

**CRITICAL**: AI assistants MUST perform these checks before Git operations:

### Automatic Checks

```bash
# 1. Check if Git repository exists
if [ ! -d .git ]; then
  echo "No Git repository found."
  # Ask user if they want to initialize
fi

# 2. Check if there are unstaged changes
git status --short

# 3. Check current branch
CURRENT_BRANCH=$(git branch --show-current)
echo "On branch: $CURRENT_BRANCH"

# 4. Check if remote exists
git remote -v

# 5. Check for unpushed commits
git log origin/main..HEAD --oneline 2>/dev/null
```

### Before Git Commands

**NEVER execute if `.git` directory exists:**
- ❌ `git init` - Repository already initialized
- ❌ `git branch -M main` - Branch may already be configured
- ❌ `git remote add origin` - Remote may already exist (check first with `git remote -v`)
- ❌ `git config user.name/email` - User configuration is personal
- ❌ Reconfiguration commands - Repository is already set up

**ALWAYS safe to execute:**
- ✅ `git status` - Check repository state
- ✅ `git add` - Stage changes
- ✅ `git commit` - Create commits (after quality checks)
- ✅ `git log` - View history
- ✅ `git diff` - View changes
- ✅ `git branch` - List branches
- ✅ `git tag` - Create tags (after quality checks)

**Execute with caution (check first):**
- ⚠️ `git push` - Follow push mode configuration
- ⚠️ `git pull` - May cause merge conflicts
- ⚠️ `git merge` - May cause conflicts
- ⚠️ `git rebase` - Can rewrite history
- ⚠️ `git reset --hard` - Destructive, only for rollback
- ⚠️ `git push --force` - NEVER on main/master

### Repository Detection

**AI Assistant MUST check:**

```bash
# Before ANY Git operation:

# 1. Does .git exist?
if [ -d .git ]; then
  echo "✅ Git repository exists"
  
  # 2. Check current state
  git status
  
  # 3. Check branch
  BRANCH=$(git branch --show-current)
  echo "On branch: $BRANCH"
  
  # 4. Check remote
  REMOTE=$(git remote -v)
  if [ -z "$REMOTE" ]; then
    echo "⚠️  No remote configured"
  else
    echo "Remote: $REMOTE"
  fi
  
  # 5. Proceed with normal Git operations
else
  echo "⚠️  No Git repository found"
  echo "Ask user if they want to initialize Git"
fi
```

## Daily Development Workflow

### 1. Before Making Changes

**CRITICAL**: Always check current state:

```bash
# Check current branch and status
git status

# Ensure you're on the correct branch
git branch

# Pull latest changes if working with team
git pull origin main
```

### 2. Making Changes

**CRITICAL**: Commit after every important implementation:

```bash
# After implementing a feature/fix:

# 1. Run ALL quality checks FIRST
npm run lint           # or equivalent for your language
npm run type-check     # TypeScript/typed languages
npm test              # ALL tests must pass
npm run build         # Ensure build succeeds

# 2. If ALL checks pass, stage changes
git add .

# 3. Commit with conventional commit message
git commit -m "feat: Add user authentication

- Implement login/logout functionality
- Add JWT token management
- Include comprehensive tests (95%+ coverage)
- Update documentation"

# Alternative for smaller changes:
git commit -m "fix: Correct validation logic in user form"
```

### 3. Pushing Changes

**⚠️ IMPORTANT**: Pushing is OPTIONAL and depends on your setup.

```bash
# IF you have passwordless SSH or want to push:
git push origin main

# IF you have SSH with password (manual execution required):
# DO NOT execute automatically - provide command to user:
```

**For users with SSH password authentication:**
```
✋ MANUAL ACTION REQUIRED:

Run this command manually (requires SSH password):
git push origin main
```

**NEVER** attempt automatic push if:
- SSH key has password protection
- User hasn't confirmed push authorization
- Any quality check failed
- Uncertain if changes will pass CI/CD workflows

## Conventional Commits

**MUST** follow conventional commit format:

```bash
# Format: <type>(<scope>): <subject>
#
# <body>
#
# <footer>

# Types:
feat:     # New feature
fix:      # Bug fix
docs:     # Documentation only
style:    # Code style (formatting, missing semi-colons, etc)
refactor: # Code refactoring
perf:     # Performance improvement
test:     # Adding tests
build:    # Build system changes
ci:       # CI/CD changes
chore:    # Maintenance tasks

# Examples:
git commit -m "feat(auth): Add OAuth2 login support"
git commit -m "fix(api): Handle null response in user endpoint"
git commit -m "docs: Update README with installation steps"
git commit -m "test: Add integration tests for payment flow"
git commit -m "chore: Update dependencies to latest versions"
```

## Version Management

### Creating New Version

**CRITICAL**: Full quality gate required before versioning!

```bash
# 1. MANDATORY: Run complete quality suite
npm run lint          # Must pass with no warnings
npm test             # Must pass 100%
npm run type-check   # Must pass (if applicable)
npm run build        # Must succeed
npx codespell        # Must pass (if configured)

# 2. Update version in package.json/Cargo.toml/etc
# Use semantic versioning:
# - MAJOR: Breaking changes (1.0.0 -> 2.0.0)
# - MINOR: New features, backwards compatible (1.0.0 -> 1.1.0)
# - PATCH: Bug fixes (1.0.0 -> 1.0.1)

# 3. Update CHANGELOG.md
# Document all changes in this version:
## [1.2.0] - 2024-01-15
### Added
- New feature X
- New feature Y

### Fixed
- Bug in component Z

### Changed
- Refactored module A

# 4. Commit version changes
git add .
git commit -m "chore: Release version 1.2.0

- Updated version to 1.2.0
- Updated CHANGELOG.md with release notes"

# 5. Create annotated tag
git tag -a v1.2.0 -m "Release version 1.2.0

Major changes:
- Feature X
- Feature Y
- Bug fix Z

All tests passing ✅
Coverage: 95%+ ✅
Linting: Clean ✅
Build: Success ✅"

# 6. OPTIONAL: Push tag (manual if SSH password)
# Only if you're CERTAIN it will pass CI/CD workflows!
```

**For users requiring manual push:**
```
✋ MANUAL ACTIONS REQUIRED:

1. Verify all quality checks passed locally
2. Push commits:
   git push origin main

3. Push tag:
   git push origin v1.2.0

Note: Tag push will trigger CI/CD workflows and may create GitHub release.
Only push if you're confident all checks will pass.
```

## Quality Gate Enforcement

### Before ANY Commit

**MANDATORY CHECKS**:

```bash
# Checklist - ALL must pass:
☐ Code formatted
☐ Linter passes (no warnings)
☐ Type check passes
☐ ALL tests pass (100%)
☐ Coverage meets threshold (95%+)
☐ Build succeeds
☐ No console errors/warnings

# Run quality check script:
npm run quality-check  # or equivalent

# If ANY check fails:
# ❌ DO NOT COMMIT
# ❌ FIX THE ISSUES FIRST
```

### Before Tag Creation

**MANDATORY CHECKS** (even stricter):

```bash
# Extended checklist - ALL must pass:
☐ All pre-commit checks passed
☐ Codespell passes (no typos)
☐ Security audit clean
☐ Dependencies up to date
☐ Documentation updated
☐ CHANGELOG.md updated
☐ Version bumped correctly
☐ All workflows would pass

# Run comprehensive check:
npm run lint
npm test
npm run type-check
npm run build
npx codespell
npm audit

# Only create tag if everything is green!
```

## Error Recovery & Rollback

### When Implementation Is Failing

If the AI is making repeated mistakes and user is frustrated:

```bash
# 1. Identify last stable commit
git log --oneline -10

# 2. Create backup branch of current work
git branch backup-failed-attempt

# 3. Hard reset to last stable version
git reset --hard <last-stable-commit-hash>

# 4. Verify stability
npm test
npm run build

# 5. Reimplement from scratch using DIFFERENT approach
# ⚠️ DO NOT repeat the same techniques that failed before
# ⚠️ Review AGENTS.md for alternative patterns
# ⚠️ Consider different architecture/design

# 6. After successful reimplementation
git branch -D backup-failed-attempt  # Delete backup if no longer needed
```

### Undo Last Commit (Not Pushed)

```bash
# Keep changes, undo commit
git reset --soft HEAD~1

# Discard changes completely
git reset --hard HEAD~1
```

### Revert Pushed Commit

```bash
# Create revert commit
git revert <commit-hash>

# Then push (manual if SSH password)
```

## Branch Strategy

### Feature Branches

```bash
# Create feature branch
git checkout -b feature/user-authentication

# Work on feature...
# Commit regularly with quality checks

# When feature complete and tested:
git checkout main
git merge feature/user-authentication

# Delete feature branch
git branch -d feature/user-authentication
```

### Hotfix Workflow

```bash
# Critical bug in production
git checkout -b hotfix/critical-security-fix

# Fix the bug
# MUST include tests
# MUST pass all quality checks

git commit -m "fix: Critical security vulnerability in auth

- Patch authentication bypass
- Add regression tests
- Update security documentation"

# Merge to main
git checkout main
git merge hotfix/critical-security-fix

# Tag immediately if production fix
git tag -a v1.2.1 -m "Hotfix: Security patch"

# Manual push if required
```

## Critical AI Assistant Rules

### Repository Initialization

**BEFORE any `git init` or setup commands:**

```
1. Check for .git directory existence
2. If .git exists:
   - ❌ STOP - Repository already configured
   - ❌ DO NOT run git init
   - ❌ DO NOT run git config
   - ❌ DO NOT run git branch -M
   - ❌ DO NOT reconfigure anything
   - ✅ Use existing repository as-is
   
3. If .git does NOT exist:
   - ✅ Ask user if they want Git initialization
   - ✅ Run initialization sequence if approved
```

### Push Command Behavior

**Based on configured push mode:**

```
Manual Mode (DEFAULT):
  ❌ NEVER execute: git push
  ✅ ALWAYS provide: "Run manually: git push origin main"
  
Prompt Mode:
  ⚠️  ALWAYS ask first: "Ready to push. Proceed? [Y/n]"
  ✅ Execute only if user confirms
  
Auto Mode:
  ⚠️  Check quality first
  ⚠️  Only if 100% confident
  ✅ Execute if all checks passed
```

### Quality Gate Enforcement

**MANDATORY checks before commit:**

```bash
# Run in this exact order:
1. npm run lint          # or language equivalent
2. npm run type-check    # if applicable
3. npm test             # ALL tests must pass
4. npm run build        # must succeed

# If ANY fails:
❌ STOP - DO NOT commit
❌ Fix issues first
❌ Re-run all checks

# If ALL pass:
✅ Safe to commit
✅ Proceed with git add and commit
```

**MANDATORY checks before tag:**

```bash
# Extended checks for version tags:
1. All commit checks above +
2. npx codespell        # no typos
3. npm audit            # no vulnerabilities
4. CHANGELOG.md updated
5. Version bumped correctly
6. Documentation current

# If ANY fails:
❌ STOP - DO NOT create tag
❌ Fix issues
❌ Re-verify everything

# Only create tag if 100% green!
```

## Best Practices

### DO's ✅

- **ALWAYS** check if .git exists before init commands
- **ALWAYS** run tests before commit
- **ALWAYS** use conventional commit messages
- **ALWAYS** update CHANGELOG for versions
- **COMMIT** after each important implementation
- **TAG** releases with semantic versions
- **VERIFY** quality gates before tagging
- **DOCUMENT** breaking changes clearly
- **REVERT** when implementation is failing repeatedly
- **ASK** user before automatic push
- **PROVIDE** manual commands for SSH password users
- **CHECK** repository state before operations
- **RESPECT** existing Git configuration

### DON'Ts ❌

- **NEVER** run `git init` if .git exists
- **NEVER** run `git config` (user-specific)
- **NEVER** reconfigure existing repository
- **NEVER** commit without passing tests
- **NEVER** commit with linting errors
- **NEVER** commit with build failures
- **NEVER** create tag without quality checks
- **NEVER** push automatically with SSH password
- **NEVER** push if uncertain about CI/CD success
- **NEVER** commit console.log/debug code
- **NEVER** commit credentials or secrets
- **NEVER** force push to main/master
- **NEVER** rewrite published history
- **NEVER** skip hooks (--no-verify)
- **NEVER** assume repository configuration

## SSH Configuration

### For Users with SSH Password

If your SSH key has password protection:

**Configuration in AGENTS.md or project settings:**

```yaml
git_workflow:
  auto_push: false
  push_mode: "manual"
  reason: "SSH key has password protection"
```

**AI Assistant Behavior:**
- ✅ Provide push commands in chat
- ✅ Wait for user manual execution
- ❌ Never attempt automatic push
- ❌ Never execute git push commands

### For Users with Passwordless SSH

```yaml
git_workflow:
  auto_push: true  # or prompt each time
  push_mode: "auto"
```

## Git Hooks

### Pre-commit Hook

Create `.git/hooks/pre-commit`:

```bash
#!/bin/sh

echo "Running pre-commit checks..."

# Run linter
npm run lint
if [ $? -ne 0 ]; then
  echo "❌ Linting failed. Commit aborted."
  exit 1
fi

# Run tests
npm test
if [ $? -ne 0 ]; then
  echo "❌ Tests failed. Commit aborted."
  exit 1
fi

# Run type check (if applicable)
if command -v tsc &> /dev/null; then
  npm run type-check
  if [ $? -ne 0 ]; then
    echo "❌ Type check failed. Commit aborted."
    exit 1
  fi
fi

echo "✅ All pre-commit checks passed!"
exit 0
```

### Pre-push Hook

Create `.git/hooks/pre-push`:

```bash
#!/bin/sh

echo "Running pre-push checks..."

# Run full test suite
npm test
if [ $? -ne 0 ]; then
  echo "❌ Tests failed. Push aborted."
  exit 1
fi

# Run build
npm run build
if [ $? -ne 0 ]; then
  echo "❌ Build failed. Push aborted."
  exit 1
fi

echo "✅ All pre-push checks passed!"
exit 0
```

Make hooks executable:
```bash
chmod +x .git/hooks/pre-commit
chmod +x .git/hooks/pre-push
```

## CI/CD Integration

### Before Providing Push Commands

**CRITICAL**: Only suggest push if confident about CI/CD success:

```
✅ Provide push command if:
- All local tests passed
- All linting passed
- Build succeeded
- Coverage meets threshold
- No warnings or errors
- Code follows AGENTS.md standards
- Similar changes passed CI/CD before

❌ DO NOT provide push command if:
- ANY quality check failed
- Uncertain about CI/CD requirements
- Making experimental changes
- First time working with this codebase
- User seems uncertain

Instead say:
"I recommend running the full CI/CD pipeline locally first to ensure 
the changes will pass. Once confirmed, you can push manually."
```

## GitHub MCP Server Integration

**If GitHub MCP Server is available**, use it for automated workflow monitoring.

### Workflow Validation After Push

```
After every git push (manual or auto):

1. Wait 5-10 seconds for workflows to trigger

2. Check workflow status via GitHub MCP:
   - List workflow runs for latest commit
   - Check status of each workflow

3. If workflows are RUNNING:
   ⏳ Report: "CI/CD workflows in progress..."
   ✅ Continue with other tasks
   ✅ Check again in next user interaction
   
4. If workflows COMPLETED:
   - All passed: ✅ Report success
   - Some failed: ❌ Fetch errors and fix

5. If workflows FAILED:
   a. Fetch complete error logs via GitHub MCP
   b. Display errors to user
   c. Analyze against AGENTS.md standards
   d. Propose specific fixes
   e. Implement fixes
   f. Run local quality checks
   g. Commit fixes
   h. Provide push command for retry
```

### Next Interaction Check

```
On every user message after a push:

if (github_mcp_available && last_push_timestamp) {
  // Check workflow status
  const status = await checkWorkflows();
  
  if (status.running) {
    console.log('⏳ CI/CD still running, will check later');
  } else if (status.failed) {
    console.log('❌ CI/CD failures detected!');
    await analyzeAndFixErrors(status.errors);
  } else {
    console.log('✅ All CI/CD workflows passed!');
  }
}
```

### Error Analysis Flow

```
When workflow fails:

1. Fetch error via GitHub MCP:
   - Workflow name
   - Job name  
   - Failed step
   - Error output
   - Full logs

2. Categorize error:
   - Test failure → Fix test or implementation
   - Lint error → Format/fix code style
   - Build error → Fix compilation issues
   - Type error → Fix type definitions
   - Coverage error → Add more tests

3. Fix following AGENTS.md:
   - Apply correct pattern from AGENTS.md
   - Add tests if needed
   - Verify locally before committing

4. Commit fix:
   git commit -m "fix: Resolve CI/CD failure - [specific issue]"

5. Provide push command:
   "Ready to retry. Run: git push origin main"

6. After next push:
   - Monitor again
   - Verify fix worked
```

### CI/CD Confidence Check

**Before suggesting push:**

```
Assess confidence in CI/CD success:

HIGH confidence (safe to push):
✅ All local checks passed
✅ Similar changes passed CI before
✅ No experimental changes
✅ Follows AGENTS.md exactly
✅ Comprehensive tests
✅ No unusual patterns

MEDIUM confidence (verify first):
⚠️ First time with this pattern
⚠️ Modified build configuration
⚠️ Changed dependencies
⚠️ Cross-platform concerns
→ Suggest: "Let's verify locally first"

LOW confidence (don't push yet):
❌ Experimental implementation
❌ Skipped some tests
❌ Uncertain about compatibility
❌ Modified CI/CD files
→ Say: "Let's run additional checks first"
```

## Troubleshooting

### Merge Conflicts

```bash
# View conflicts
git status

# Edit conflicted files (marked with <<<<<<<, =======, >>>>>>>)

# After resolving:
git add <resolved-files>
git commit -m "fix: Resolve merge conflicts"
```

### Accidental Commit

```bash
# Undo last commit, keep changes
git reset --soft HEAD~1

# Make corrections
# Re-commit properly
```

### Lost Commits

```bash
# View all actions
git reflog

# Recover lost commit
git checkout <commit-hash>
git checkout -b recovery-branch
```

<!-- GIT:END -->
